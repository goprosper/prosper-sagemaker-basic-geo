{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Prosper Propensity Models (BASIC-GEO)\n",
    "\n",
    "This notebook illustrates the use of a subset of Prosper Propensity Models based on a particular feature set called basic-geo. These models may be used for realtime inference and batch transform jobs. \n",
    "\n",
    "## Input Variables\n",
    "\n",
    "**Gender** (Integer, 0-1)    \n",
    "0 = Female  \n",
    "1 = Male \n",
    "  \n",
    "**Age Range** (Integer, 1-6)  \n",
    "1 = 18-24   \n",
    "2 = 25-34  \n",
    "3 = 35-44  \n",
    "4 = 45-54  \n",
    "5 = 55-64  \n",
    "6 = 65+  \n",
    "  \n",
    "**Household Income** (Integer, 0-24)  \n",
    " 0 = Less than \\\\$10,000  \n",
    " 1 = \\\\$10,000 to \\\\$14,999  \n",
    " 2 = \\\\$15,000 to \\\\$19,999  \n",
    " 3 = \\\\$20,000 to \\\\$24,999  \n",
    " 4 = \\\\$25,000 to \\\\$29,999  \n",
    " 5 = \\\\$30,000 to \\\\$34,999  \n",
    " 6 = \\\\$35,000 to \\\\$39,999  \n",
    " 7 = \\\\$40,000 to \\\\$44,999  \n",
    " 8 = \\\\$45,000 to \\\\$49,999  \n",
    " 9 = \\\\$50,000 to \\\\$54,999  \n",
    " 10 = \\\\$55,000 to \\\\$59,999  \n",
    " 11 = \\\\$60,000 to \\\\$64,999  \n",
    " 12 = \\\\$65,000 to \\\\$69,999  \n",
    " 13 = \\\\$70,000 to \\\\$74,999  \n",
    " 14 = \\\\$75,000 to \\\\$79,999  \n",
    " 15 = \\\\$80,000 to \\\\$84,999  \n",
    " 16 = \\\\$85,000 to \\\\$89,999  \n",
    " 17 = \\\\$90,000 to \\$94,999  \n",
    " 18 = \\\\$95,000 to \\\\$99,999  \n",
    " 19 = \\\\$100,000 to \\\\$109,999  \n",
    " 20 = \\\\$110,000 to \\\\$119,999  \n",
    " 21 = \\\\$120,000 to \\\\$129,999  \n",
    " 22 = \\\\$130,000 to \\\\$139,999  \n",
    " 23 = \\\\$140,000 to \\\\$149,999  \n",
    " 24 = \\\\$150,000 or more  \n",
    " \n",
    " **Zip Code** (5 digit zip code as integer)  \n",
    "\n",
    "\n",
    "## Preprocessing the Zip Code\n",
    "\n",
    "The Prosper Models require that the zip code be replaced by a set of 25 binary variables that represent special information regarding the zip. Prosper provides a file that maps every zip code into two integer values (division and cluster). These values are then converted into a set of binary values in a manner similar to one-hot encoding. The mapping file as well as the conversion routines are provided below.\n",
    "\n",
    "## Result\n",
    "\n",
    "The Prosper Model returns a score between 0 and 1 that represents the probability that the person has the target attribute.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "***\n",
    "  \n",
    "# Initialize notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sm\n",
    "\n",
    "# Specify the ARN of the model package you will be using. You can get this\n",
    "# from the sagemaker console after you subscribe to the model package.\n",
    "model_package_arn = 'arn:aws:sagemaker:us-east-2:214666064132:model-package/use-uber-reg-basic-geo'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load zip code dictionary and define zip feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Load the zip code dictionary used to prepare the data.\n",
    "# The dictionary key is the zip code.  The values are tuples containing the cluster\n",
    "# and division.\n",
    "\n",
    "zip_dict = {}\n",
    "  \n",
    "with open('prosper_data/zip_features.csv', newline='') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    \n",
    "    # skip the header\n",
    "    next(csvreader)\n",
    "\n",
    "    for row in csvreader:\n",
    "        zip_dict[int(row[0])] = (int(row[1]), int(row[2]))  # (cluster, division)\n",
    "        \n",
    "print(\"Zip dictionary loaded\")\n",
    "            \n",
    "#\n",
    "# get_zip_feature_list returns a list of the 25 special features\n",
    "# associated with the provided zip_code. These should be appended to the inference\n",
    "# input in place of the zip code.\n",
    "#\n",
    "def get_zip_feature_list(zip_code):\n",
    "    \n",
    "    # Retrieve cluster and division from dictionary. \n",
    "    # If zip is not found, return all zeros.\n",
    "    try:\n",
    "        (cluster, division) = zip_dict[int(zip_code)]\n",
    "    except KeyError:\n",
    "        return ['0'] * 25\n",
    "    \n",
    "    cluster_list = ['0'] * 16  # initialize to 16 zeros\n",
    "    cluster_list[cluster] = '1'\n",
    "    \n",
    "    division_list = ['0'] * 9  # initialize to 9 zeros\n",
    "    division_list[division] = '1'\n",
    "    \n",
    "    return division_list + cluster_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "___\n",
    "\n",
    "# Realtime Inference Example\n",
    "1. Deploy model to endpoint\n",
    "2. Submit inference requests to the endpoint\n",
    "3. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model to an endpoint\n",
    "Typically, the model will be deployed to an endpoint and allowed to run. Other processes may then submit inference requests to that endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Set endpoint name. You may replace the following with any name you like. \n",
    "endpoint_name = 'prosper-test-endpoint-' + time.strftime(\"%Y%m%d%H%M%S\", time.localtime())  \n",
    "\n",
    "# Create model from model package\n",
    "print(f'model_package_arn: {model_package_arn}')\n",
    "print(f'endpoint_name: {endpoint_name}')\n",
    "model = sm.ModelPackage(\n",
    "            role=sm.get_execution_role(),\n",
    "            model_package_arn=model_package_arn,\n",
    "            sagemaker_session=sm.Session())\n",
    "\n",
    "# Deploy the model to an endpoint. Be sure to delete the endpoint when you are finished with it.\n",
    "# By default, this method waits until the endpoint is deployed. This could take a while.\n",
    "# To have the API return immediately, set the wait parameter to false. Note, however, that you\n",
    "# cannot submit a request to the endpoint until it is in service. The easy way to check the status is\n",
    "# by using the sagemaker console.\n",
    "model.deploy(1, 'ml.m4.xlarge', endpoint_name=endpoint_name)\n",
    "\n",
    "print(f'\\nEndpoint {endpoint_name} is now in service')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit a realtime inference request to the endpoint created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictor for endpoint created above\n",
    "predictor = sm.predictor.RealTimePredictor(endpoint_name, content_type='text/csv')\n",
    "\n",
    "# Sample request\n",
    "# Male\n",
    "gender = 1\n",
    "# Age Range: 55-64\n",
    "age_range = 5\n",
    "# Household Income: $150,000+\n",
    "household_income_range = 24\n",
    "# zip features: 43017\n",
    "# join the zip feature list into a comma-delimited string\n",
    "zip_features = \",\".join(get_zip_feature_list(43017))\n",
    "\n",
    "# format request data as comma-delimited string\n",
    "request_data = f'{gender},{age_range},{household_income_range},{zip_features}'\n",
    "print(f'Request Data: {request_data}')\n",
    "\n",
    "# Submit the request to the endpoint.\n",
    "# By default, the result is returned as a sequence of bytes. We decode it as utf-8 string.\n",
    "# Note that there are parameters available for serializing and deserializing input and output data.\n",
    "result = predictor.predict(request_data).decode('utf-8')\n",
    "\n",
    "# print the result. This is the probability that the person with the requested parameters are in the\n",
    "# target class.\n",
    "print(f'Response (probability): {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.session.Session().delete_endpoint(endpoint_name)\n",
    "sm.session.Session().delete_endpoint_config(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "***\n",
    "    \n",
    "# Batch Transform Example\n",
    "1. Prepare the input file\n",
    "2. Create the transform job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the input file\n",
    "1. Replace the zip codes in the sample input file with the special zip features\n",
    "2. Upload the prepared file to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# A sample input file (data/sample_basic_zip.csv) is provided with this notebook.\n",
    "# First, we need to convert the zip codes in the sample file to the special\n",
    "# binary features.\n",
    "\n",
    "with open('sample_transform_input.csv', 'w', newline='') as f_out:\n",
    "    writer = csv.writer(f_out)\n",
    "\n",
    "    with open('prosper_data/sample_basic_zip.csv', newline='') as f_in:\n",
    "        csvreader = csv.reader(f_in)\n",
    "        for inrow in csvreader:\n",
    "            # retain first three columns: gender, age, income\n",
    "            outrow = [inrow[0], inrow[1], inrow[2]]\n",
    "            \n",
    "            # append feature list for zip code\n",
    "            outrow = outrow + get_zip_feature_list(inrow[3])\n",
    "            \n",
    "            writer.writerow(outrow)\n",
    "\n",
    "\n",
    "# The transform job expects its input file to to live in S3.  We upload the converted file\n",
    "# to the default bucket with key_prefix of prosper-sample-data. You\n",
    "# can upload to any bucket and key you like if you specify the bucket and key_prefix parameters.\n",
    "\n",
    "transform_input = sm.Session().upload_data('sample_transform_input.csv', key_prefix='prosper-sample-data')\n",
    "print(f'transform input: {transform_input}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the transform job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model from model package\n",
    "model = sm.ModelPackage(\n",
    "            role=sm.get_execution_role(),\n",
    "            model_package_arn=model_package_arn,\n",
    "            sagemaker_session=sm.Session())\n",
    "\n",
    "# Create the transformer\n",
    "# A variety of parameters may be specified here including the output path where\n",
    "# SageMaker will send the results of the transform. Since we do not specify the output,\n",
    "# Sagemaker will leave the results in the default bucket. We will retrieve this location \n",
    "# below so that we can inspect the output.\n",
    "transformer = model.transformer(1, 'ml.m4.xlarge')\n",
    "\n",
    "# Run the transform job.\n",
    "#\n",
    "# By default, the output file contains only the inference result for each row.\n",
    "# You can use the output_filter parameter to include any of the input columns. Review also\n",
    "# input_filter which allows you to filter the parameters passed as input to the transformer.\n",
    "# The combination of input_filter and output_filter gives you a lot of flexibility.\n",
    "#\n",
    "# By default, the API does not wait for the transform job to complete. You can control this with\n",
    "# the wait parameter.\n",
    "#\n",
    "transformer.transform(transform_input, content_type='text/csv')\n",
    "\n",
    "# The transform job sets the output path in the output_path member.\n",
    "print(f'Transform output: {transformer.output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
